{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b835f9",
   "metadata": {},
   "source": [
    "# ... modello pre-trainato su Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3225e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pytesseract\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773ea1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA Graphics Device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228ca39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu128\n",
      "12.8\n",
      "NVIDIA Graphics Device\n",
      "(12, 0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "print(torch.cuda.get_device_capability(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49801023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_timer_image(timer_region):\n",
    "    \"\"\"Preelabora l'immagine del timer per migliorare l'OCR (versione migliorata)\"\"\"\n",
    "    # Converti in scala di grigi\n",
    "    gray = cv2.cvtColor(timer_region, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Ingrandisci l'immagine\n",
    "    gray = cv2.resize(gray, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Sfoca leggermente per ridurre il rumore\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Binarizzazione con Otsu\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Se necessario, inverte bianco/nero\n",
    "    white_pixels = np.sum(thresh == 255)\n",
    "    black_pixels = np.sum(thresh == 0)\n",
    "    if white_pixels < black_pixels:\n",
    "        thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    return thresh\n",
    "\n",
    "\n",
    "def read_timer_text(timer_region, timestamp):\n",
    "    \"\"\"Legge il testo dal timer usando OCR\"\"\"\n",
    "    processed_img = preprocess_timer_image(timer_region)\n",
    "    \n",
    "    config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789:'\n",
    "    raw_text = pytesseract.image_to_string(processed_img, config=config).strip()\n",
    "    print(f\"[OCR] Testo grezzo: '{raw_text}'\")\n",
    "    \n",
    "    # Parse the target timestamp\n",
    "    parts = timestamp.split(\":\")\n",
    "    searched_mins = int(parts[0])\n",
    "    searched_secs = int(parts[1])\n",
    "\n",
    "    # Normalizza vari casi possibili\n",
    "    if searched_mins == 0:\n",
    "        # For timestamps like 00:XX, we're mostly concerned with seconds\n",
    "        raw_text = ''.join(char for char in raw_text if char.isdigit())\n",
    "        if len(raw_text) >= 2:\n",
    "            # Extract just the seconds part\n",
    "            try:\n",
    "                secs = int(raw_text[-3:-1])\n",
    "                print(f\"[OCR] Testo riconosciuto :ssd... '00:{secs:02d}'\")\n",
    "                return 0, secs\n",
    "            except ValueError:\n",
    "                return None\n",
    "        return None\n",
    "    else:\n",
    "        # Try to parse MM:SS format\n",
    "        match = re.search(r'(\\d{1,2}):(\\d{2})', raw_text)\n",
    "        if match:\n",
    "            mins = int(match.group(1))\n",
    "            secs = int(match.group(2))\n",
    "            print(f\"[OCR] Testo riconosciuto mm:ss... {mins}:{secs:02d}\")\n",
    "            return mins, secs\n",
    "        \n",
    "        # Try to parse continuous digits as minutes and seconds\n",
    "        match = re.search(r'(\\d{3,4})', raw_text)\n",
    "        if match and len(match.group(1)) >= 3:\n",
    "            digits = match.group(1)\n",
    "            mins = int(digits[:-2])\n",
    "            secs = int(digits[-2:])\n",
    "            print(f\"[OCR] Testo riconosciuto mmss... {mins}:{secs:02d}\")\n",
    "            return mins, secs\n",
    "            \n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_frames_by_timestamp(video_path, output_dir=\"/home/diego/Documents/GitHub/NBA/Computer_vision/Frames_of_shot\"):\n",
    "    \"\"\"Estrae i frame corrispondenti ai timestamp specificati\"\"\"\n",
    "    # Get video file name without extension for output naming\n",
    "    target_timestamp = video_path[-9:-4]\n",
    "    video_filename = os.path.basename(video_path)\n",
    "    name_file = os.path.splitext(video_filename)[0]\n",
    "    \n",
    "    found_timestamps = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Parse the target timestamp\n",
    "    parts = target_timestamp.split(\":\")\n",
    "    searched_mins, searched_secs = int(parts[0]), int(parts[1])\n",
    "    standardized_target = f\"{searched_mins:02d}:{searched_secs:02d}\"\n",
    "\n",
    "    print(f\"Cercando il timestamp: {standardized_target}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Impossibile aprire il video: {video_path}\")\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_duration = total_frames / fps\n",
    "    \n",
    "    print(f\"Video: {os.path.basename(video_path)}\")\n",
    "    print(f\"Durata: {video_duration:.2f} secondi ({total_frames} frames)\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    \n",
    "    check_interval = max(1, int(fps / 2))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for frame_idx in range(0, total_frames, check_interval):\n",
    "        if frame_idx % (check_interval * 10) == 0:\n",
    "            progress = (frame_idx / total_frames) * 100\n",
    "            elapsed = time.time() - start_time\n",
    "            remaining = (elapsed / (frame_idx + 1)) * (total_frames - frame_idx) if frame_idx > 0 else 0\n",
    "            print(f\"Progresso: {progress:.1f}% (tempo rimanente stimato: {remaining:.1f}s)\")\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        results = model(frame, conf=0.5)  # Assuming model is defined elsewhere\n",
    "        \n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                conf = float(box.conf[0])\n",
    "                \n",
    "                if conf > 0.5:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    timer_region = frame[y1:y2, x1:x2].copy()\n",
    "                    \n",
    "                    # Salva la regione del timer per debug (opzionale)\n",
    "                    #debug_path = os.path.join(output_dir, f\"timer_debug_{frame_idx}.jpg\")\n",
    "                    #cv2.imwrite(debug_path, timer_region)\n",
    "                    \n",
    "                    timer_text = read_timer_text(timer_region, target_timestamp)\n",
    "                    \n",
    "                    if timer_text:\n",
    "                        found_mins, found_secs = timer_text\n",
    "                        \n",
    "                        if found_mins == searched_mins and found_secs == searched_secs:\n",
    "                            out_filename = f\"{name_file}_{found_mins:02d}_{found_secs:02d}_frame{frame_idx}.jpg\"\n",
    "                            output_path = os.path.join(output_dir, out_filename)\n",
    "                            cv2.imwrite(output_path, frame)                            \n",
    "                            found_timestamp = f\"{found_mins:02d}:{found_secs:02d}\"\n",
    "                            found_timestamps.append(found_timestamp)\n",
    "                            print(f\"Trovato timestamp {found_mins:02d}:{found_secs:02d} nel frame {frame_idx}\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if not found_timestamps:\n",
    "        print(f\"Il timestamp {standardized_target} non Ã¨ stato trovato\")\n",
    "    \n",
    "    return found_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a1a4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "0\n",
      "Cercando il timestamp: 11:48\n",
      "Video: bos-vs-nyk-0022300065_1_11:48.mp4\n",
      "Durata: 9.57 secondi (574 frames)\n",
      "FPS: 60.0\n",
      "Progresso: 0.0% (tempo rimanente stimato: 0.0s)\n",
      "\n",
      "0: 384x640 1 timer, 51.0ms\n",
      "Speed: 4.1ms preprocess, 51.0ms inference, 97.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:54'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:54\n",
      "\n",
      "0: 384x640 1 timer, 6.4ms\n",
      "Speed: 3.1ms preprocess, 6.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:53'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:53\n",
      "\n",
      "0: 384x640 1 timer, 6.8ms\n",
      "Speed: 1.9ms preprocess, 6.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:53'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:53\n",
      "\n",
      "0: 384x640 1 timer, 4.7ms\n",
      "Speed: 1.2ms preprocess, 4.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '1:52'\n",
      "[OCR] Testo riconosciuto mm:ss... 1:52\n",
      "\n",
      "0: 384x640 1 timer, 5.5ms\n",
      "Speed: 4.6ms preprocess, 5.5ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:52'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:52\n",
      "\n",
      "0: 384x640 1 timer, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:51'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:51\n",
      "\n",
      "0: 384x640 1 timer, 5.8ms\n",
      "Speed: 2.1ms preprocess, 5.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:51'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:51\n",
      "\n",
      "0: 384x640 1 timer, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:50'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:50\n",
      "\n",
      "0: 384x640 1 timer, 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:50'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:50\n",
      "\n",
      "0: 384x640 1 timer, 5.4ms\n",
      "Speed: 1.1ms preprocess, 5.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:49'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:49\n",
      "Progresso: 52.3% (tempo rimanente stimato: 3.1s)\n",
      "\n",
      "0: 384x640 1 timer, 6.4ms\n",
      "Speed: 1.6ms preprocess, 6.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:49'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:49\n",
      "\n",
      "0: 384x640 1 timer, 6.5ms\n",
      "Speed: 1.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:48'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:48\n",
      "Trovato timestamp 11:48 nel frame 330\n",
      "\n",
      "0: 384x640 1 timer, 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:48'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:48\n",
      "Trovato timestamp 11:48 nel frame 360\n",
      "\n",
      "0: 384x640 1 timer, 6.3ms\n",
      "Speed: 2.7ms preprocess, 6.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:47'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:47\n",
      "\n",
      "0: 384x640 1 timer, 5.8ms\n",
      "Speed: 2.3ms preprocess, 5.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:47'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:47\n",
      "\n",
      "0: 384x640 1 timer, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:46'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:46\n",
      "\n",
      "0: 384x640 1 timer, 6.0ms\n",
      "Speed: 1.2ms preprocess, 6.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:46'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:46\n",
      "\n",
      "0: 384x640 1 timer, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:45'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:45\n",
      "\n",
      "0: 384x640 1 timer, 6.8ms\n",
      "Speed: 1.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:45'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:45\n",
      "\n",
      "0: 384x640 1 timer, 6.2ms\n",
      "Speed: 1.3ms preprocess, 6.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:44'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:44\n",
      "Timestamp trovati: ['11:48', '11:48']\n",
      "VIDEO NOT FOUND\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "1\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2\n",
      "Cercando il timestamp: 11:10\n",
      "Video: bos-vs-nyk-0022300065_1_11:10.mp4\n",
      "Durata: 10.52 secondi (631 frames)\n",
      "FPS: 60.0\n",
      "Progresso: 0.0% (tempo rimanente stimato: 0.0s)\n",
      "\n",
      "0: 384x640 (no detections), 5.2ms\n",
      "Speed: 1.4ms preprocess, 5.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.2ms\n",
      "Speed: 1.8ms preprocess, 6.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.9ms preprocess, 5.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 timer, 5.7ms\n",
      "Speed: 1.2ms preprocess, 5.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:12'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:12\n",
      "\n",
      "0: 384x640 1 timer, 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:12'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:12\n",
      "\n",
      "0: 384x640 1 timer, 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:12'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:12\n",
      "\n",
      "0: 384x640 1 timer, 7.8ms\n",
      "Speed: 3.8ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:12'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:12\n",
      "\n",
      "0: 384x640 1 timer, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:12'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:12\n",
      "Progresso: 47.5% (tempo rimanente stimato: 1.2s)\n",
      "\n",
      "0: 384x640 1 timer, 5.6ms\n",
      "Speed: 3.0ms preprocess, 5.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:12'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:12\n",
      "\n",
      "0: 384x640 1 timer, 5.6ms\n",
      "Speed: 1.9ms preprocess, 5.6ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:12'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:12\n",
      "\n",
      "0: 384x640 1 timer, 6.2ms\n",
      "Speed: 1.6ms preprocess, 6.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:12'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:12\n",
      "\n",
      "0: 384x640 1 timer, 5.8ms\n",
      "Speed: 3.1ms preprocess, 5.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:12'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:12\n",
      "\n",
      "0: 384x640 1 timer, 8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:11'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:11\n",
      "\n",
      "0: 384x640 1 timer, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:11'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:11\n",
      "\n",
      "0: 384x640 1 timer, 6.5ms\n",
      "Speed: 2.2ms preprocess, 6.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:10'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:10\n",
      "Trovato timestamp 11:10 nel frame 480\n",
      "\n",
      "0: 384x640 1 timer, 6.3ms\n",
      "Speed: 2.1ms preprocess, 6.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:10'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:10\n",
      "Trovato timestamp 11:10 nel frame 510\n",
      "\n",
      "0: 384x640 1 timer, 5.2ms\n",
      "Speed: 2.6ms preprocess, 5.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:09'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:09\n",
      "\n",
      "0: 384x640 1 timer, 5.7ms\n",
      "Speed: 2.5ms preprocess, 5.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:09'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:09\n",
      "Progresso: 95.1% (tempo rimanente stimato: 0.2s)\n",
      "\n",
      "0: 384x640 1 timer, 6.2ms\n",
      "Speed: 4.0ms preprocess, 6.2ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:08'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:08\n",
      "\n",
      "0: 384x640 1 timer, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '11:08'\n",
      "[OCR] Testo riconosciuto mm:ss... 11:08\n",
      "Timestamp trovati: ['11:10', '11:10']\n",
      "VIDEO NOT FOUND\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "3\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "4\n",
      "Cercando il timestamp: 10:42\n",
      "Video: bos-vs-nyk-0022300065_1_10:42.mp4\n",
      "Durata: 6.82 secondi (409 frames)\n",
      "FPS: 60.0\n",
      "Progresso: 0.0% (tempo rimanente stimato: 0.0s)\n",
      "\n",
      "0: 384x640 1 timer, 7.1ms\n",
      "Speed: 3.0ms preprocess, 7.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:46'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:46\n",
      "\n",
      "0: 384x640 1 timer, 7.4ms\n",
      "Speed: 2.2ms preprocess, 7.4ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:45'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:45\n",
      "\n",
      "0: 384x640 1 timer, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:45'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:45\n",
      "\n",
      "0: 384x640 1 timer, 6.8ms\n",
      "Speed: 1.3ms preprocess, 6.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:44'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:44\n",
      "\n",
      "0: 384x640 1 timer, 5.4ms\n",
      "Speed: 1.8ms preprocess, 5.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:44'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:44\n",
      "\n",
      "0: 384x640 1 timer, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:43'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:43\n",
      "\n",
      "0: 384x640 1 timer, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:43'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:43\n",
      "\n",
      "0: 384x640 1 timer, 5.7ms\n",
      "Speed: 2.1ms preprocess, 5.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:42'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:42\n",
      "Trovato timestamp 10:42 nel frame 210\n",
      "\n",
      "0: 384x640 1 timer, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:42'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:42\n",
      "Trovato timestamp 10:42 nel frame 240\n",
      "\n",
      "0: 384x640 1 timer, 7.3ms\n",
      "Speed: 2.6ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:4'\n",
      "Progresso: 73.3% (tempo rimanente stimato: 0.7s)\n",
      "\n",
      "0: 384x640 1 timer, 6.4ms\n",
      "Speed: 1.8ms preprocess, 6.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:41'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:41\n",
      "\n",
      "0: 384x640 1 timer, 7.4ms\n",
      "Speed: 3.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[OCR] Testo grezzo: '10:40'\n",
      "[OCR] Testo riconosciuto mm:ss... 10:40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m video_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/home/diego/Documents/GitHub/NBA/Video_bos/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mvideoID\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m video_path \u001b[38;5;129;01min\u001b[39;00m tutti_i_video:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     found = \u001b[43mextract_frames_by_timestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTimestamp trovati: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfound\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m     count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mextract_frames_by_timestamp\u001b[39m\u001b[34m(video_path, output_dir)\u001b[39m\n\u001b[32m    107\u001b[39m     remaining = (elapsed / (frame_idx + \u001b[32m1\u001b[39m)) * (total_frames - frame_idx) \u001b[38;5;28;01mif\u001b[39;00m frame_idx > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProgresso: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprogress\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% (tempo rimanente stimato: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremaining\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m ret, frame = cap.read()\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Carica il modello addestrato\n",
    "model = YOLO('/home/diego/Documents/GitHub/NBA/Computer_vision/timer_detector/weights/best.pt')\n",
    "\n",
    "# Percorso della cartella con i video\n",
    "cartella_video = \"/home/diego/Documents/GitHub/NBA/Video_bos\"\n",
    "\n",
    "# Estensioni video supportate\n",
    "estensioni_video = ['.mp4', '.avi', '.mov', '.mkv']\n",
    "\n",
    "# Trova tutti i file video nella cartella\n",
    "tutti_i_video = [\n",
    "    os.path.join(cartella_video, f) for f in os.listdir(cartella_video)\n",
    "    if os.path.isfile(os.path.join(cartella_video, f)) and any(f.lower().endswith(est) for est in estensioni_video)\n",
    "]\n",
    "\n",
    "with open('/home/diego/Documents/GitHub/NBA/database_bos.json', 'r') as f:\n",
    "    lines = [json.loads(line) for line in f]\n",
    "\n",
    "df_bos = pd.DataFrame(lines)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for index, row in df_bos.iterrows():\n",
    "    print('\\n-----------------------------------------------------------\\n')\n",
    "    print(index)\n",
    "    if row[\"videoID\"]:\n",
    "        video_path = f\"/home/diego/Documents/GitHub/NBA/Video_bos/{row['videoID']}\"\n",
    "\n",
    "        if video_path in tutti_i_video:\n",
    "            found = extract_frames_by_timestamp(video_path)\n",
    "            print(f\"Timestamp trovati: {found}\")\n",
    "            count += 1\n",
    "\n",
    "        if count == 5:\n",
    "            break\n",
    "        else:\n",
    "            print(\"VIDEO NOT FOUND\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
